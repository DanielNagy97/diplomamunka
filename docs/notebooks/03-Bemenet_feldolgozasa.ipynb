{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8e435d",
   "metadata": {},
   "source": [
    "# Bemenet feldolgozása\n",
    "\n",
    "Ezen notebook kiegészítséként szolgál a dolgozat 3. fejezetéhez.\n",
    "\n",
    "## Tartalomjegyzék\n",
    "1. [Természetes nyelvi szöveg feldolgozása](#Természetes-nyelvi-szöveg-feldolgozása)\n",
    "2. [Strukturált adatok megalkotása](#Strukturált-adatok-megalkotása)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a50ccd6",
   "metadata": {},
   "source": [
    "## Természetes nyelvi szöveg feldolgozása\n",
    "\n",
    "A bemeneti mondat egy egyszerű normalizálási folyamaton megy keresztül, hogy a további feldolgozást megkönnyítse. A normalizálási folyamat a következő:\n",
    "\n",
    "\n",
    "- Írásjelek eltávolítása\n",
    "- A szöveg kisbetűssé tétele\n",
    "- A szavak kigyűjtése (tokenek megalkotása)\n",
    "- A százalékos értékeket jelző tokenek szerializálása\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda03b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Írásjelek eltávolítása\n",
    "def remove_punctuations(input_text):\n",
    "    punctuations = [\".\", \",\", \":\", \";\", \"!\", \"?\"]\n",
    "\n",
    "    result_text = input_text\n",
    "    for punctuation in punctuations:\n",
    "        result_text = result_text.replace(punctuation, \"\")\n",
    "    return result_text\n",
    "\n",
    "# Szöveg kisbetűssé tétele\n",
    "def make_lowercase(input_text):\n",
    "    lowercase_text = input_text.lower()\n",
    "    return lowercase_text\n",
    "\n",
    "# A szavak kigyűjtése (tokenek megalkotása)\n",
    "def tokenize_text(input_text):\n",
    "    tokens = input_text.split()\n",
    "    return tokens\n",
    "\n",
    "# A százalékos értékeket jelző tokenek szerializálása\n",
    "def serialize_percentage_tokens(tokens):\n",
    "    serialized_tokens = tokens.copy()\n",
    "    percentage_symbols = [\"%\", \"százalék\"]\n",
    "    unused_tokens = []\n",
    "    for i in range(len(serialized_tokens)):\n",
    "        for percentage_symbol in percentage_symbols:\n",
    "            if percentage_symbol == serialized_tokens[i]:\n",
    "                if(serialized_tokens[i-1].isnumeric()):\n",
    "                    serialized_tokens[i-1] = serialized_tokens[i-1]+\"%\"\n",
    "                unused_tokens.append(serialized_tokens[i])\n",
    "\n",
    "    for i in unused_tokens:\n",
    "        serialized_tokens.remove(i)\n",
    "\n",
    "    return serialized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515a9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(input_text):\n",
    "    normalized_text = remove_punctuations(input_text)\n",
    "    normalized_text = make_lowercase(normalized_text)\n",
    "    tokens = tokenize_text(normalized_text)\n",
    "    tokens = serialize_percentage_tokens(tokens)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15de9a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'képen', 'megfigyelhető', 'egy', 'macska', 'amely', '20%-ban', 'eb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A bemeneti mondat normalizálása és tokenek megalkotása\n",
    "input_sentence = \"A képen megfigyelhető egy macska, amely 20%-ban eb!\"\n",
    "tokens = normalize_text(input_sentence)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5503e",
   "metadata": {},
   "source": [
    "## Strukturált adatok megalkotása\n",
    "\n",
    "Ha a bemeneti mondat normalizálásra került, úgy előállítható belőle a strukturált adat, amely jelen esetben python dictionary formátumban kerül megalkotásra.\n",
    "\n",
    "A dolgozatom ezen része nem terjed ki olyan részletesen a Természetes Nyelvi Szövegfeldolgozásra, a rendelkezésre álló adatok hiányában egy egyszerűbb megoldást választottam, amely szinonima szótár segítségével osztályozza a megfelelő tokeneket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55917721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Szinonímák a https://szinonimaszotar.hu weboldalról\n",
    "\n",
    "synonyms = {\n",
    "    \"cat\": [\"macska\", \"cica\", \"cicus\", \"cirmos\", \"cicamica\", \"kandúr\", \"macsi\", \"macsek\", \"cicó\", \"cila\", \"macs\", \"cilamila\", \"macskusz\", \"cicuska\", \"ciculi\", \"cirmi\", \"cicuka\", \"cicmic\", \"cic\", \"ciccancs\", \"kismacska\", \"mafka\", \"kiscica\"],\n",
    "    \"dog\": [\"kutya\", \"eb\", \"kutyus\", \"kutyuli\", \"blöki\", \"véreb\", \"öleb\", \"kutyuska\", \"csahos\", \"házőrző\", \"kutyi\", \"bolhazsák\", \"kutyi-mutyi\", \"kutyuli-mutyuli\", \"vahúr\", \"négylábú\", \"kutyu\", \"kutyóka\"],\n",
    "    \"wild\": [\"vadállat\", \"vad\", \"szörny\", \"szörnyeteg\", \"fenevad\", \"bestia\", \"dúvad\", \"fúria\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4e3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenek tartalmazásának vizsgálata\n",
    "\n",
    "def compare_two_tokens(token_a, token_b):\n",
    "    best_match = 0.0\n",
    "    offset = 0\n",
    "    while(offset <= len(token_b) - len(token_a)):\n",
    "        count = 0\n",
    "        for i in range(len(token_a)):\n",
    "            if(token_a[i] == token_b[offset + i]):\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "        match_value = count/len(token_a)\n",
    "\n",
    "        if(match_value > best_match):\n",
    "            best_match = match_value\n",
    "        offset += 1\n",
    "    return best_match\n",
    "\n",
    "def find_best_match_for_token_among_tokens(test_token, tokens):\n",
    "    best_match = 0.0\n",
    "    for token in tokens:\n",
    "        match_value = compare_two_tokens(token, test_token)\n",
    "        if(match_value > best_match):\n",
    "            best_match = match_value\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c742ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Osztályok azonosítása a szinonímák tartalmazása szerint\n",
    "def find_classes(tokens, threshold):\n",
    "    result_classes = []\n",
    "    for i in range(len(tokens)):\n",
    "        for key in synonyms.keys():\n",
    "            match_value =\\\n",
    "                find_best_match_for_token_among_tokens(\n",
    "                    tokens[i],\n",
    "                    synonyms[key]\n",
    "                )\n",
    "            if(match_value >= threshold):\n",
    "                found_class = {\"token_id\" : i, \"class\" : key}\n",
    "                if not found_class in result_classes:\n",
    "                    result_classes.append(found_class)\n",
    "    return result_classes\n",
    "\n",
    "# A bemenetben megadott százalékos értékek kikeresése a tokenekből\n",
    "def find_percentage_values(tokens):\n",
    "    res = []\n",
    "    for i in range(len(tokens)):\n",
    "        if \"%\" in tokens[i]:\n",
    "            prob = int(tokens[i].split(\"%\")[0]) / 100\n",
    "            found_class = {\"token_id\" : i, \"value\" : prob}\n",
    "            if not found_class in res:\n",
    "                res.append(found_class)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1214c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A kimeneti python dictionary elkészítése a talált osztályok és értékek alapján\n",
    "def make_dict_from_classes(res_classes, res_probs):\n",
    "    class_names = synonyms.keys()\n",
    "    base_data = dict()\n",
    "\n",
    "    for class_entity in class_names:\n",
    "        base_data[class_entity] = 0.0\n",
    "\n",
    "    if(len(res_probs) > 0):\n",
    "        found_classes = []\n",
    "        sums_of_prod = 0\n",
    "        for i in range(len(res_probs)):\n",
    "            for j in range(len(res_classes)):\n",
    "                if(res_probs[i][\"token_id\"] < res_classes[j][\"token_id\"]):\n",
    "                    base_data[res_classes[j]['class']] = res_probs[i]['value']\n",
    "                    sums_of_prod += res_probs[i]['value']\n",
    "                    found_classes.append(res_classes[j])\n",
    "                    break\n",
    "        if(sums_of_prod != 1):\n",
    "            if(len(found_classes) < len(res_classes)):\n",
    "                for found_class in found_classes:\n",
    "                    res_classes.remove(found_class)\n",
    "                for res_class in res_classes:\n",
    "                    base_data[res_class['class']] = (1 - sums_of_prod) / len(res_classes)\n",
    "            elif(len(found_classes) == len(res_classes)):\n",
    "                remaining_classes = list(class_names)\n",
    "                for found_class in found_classes:\n",
    "                    remaining_classes.remove(found_class['class'])\n",
    "                for remaining_class in remaining_classes:\n",
    "                    base_data[remaining_class] = (1 - sums_of_prod) / len(remaining_classes)\n",
    "        \n",
    "    else:\n",
    "        for found_class in map(lambda x: x[\"class\"], res_classes):\n",
    "            base_data[found_class] = 1 / len(res_classes)\n",
    "    return base_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8526ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_structured_data(tokens, threshold):\n",
    "    result_classes = find_classes(tokens, threshold)\n",
    "    result_percentages = find_percentage_values(tokens)\n",
    "        \n",
    "    return make_dict_from_classes(result_classes, result_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef639548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bementi mondat: A képen megfigyelhető egy macska, amely 20%-ban eb!\n",
      "\n",
      "Tokenek: ['a', 'képen', 'megfigyelhető', 'egy', 'macska', 'amely', '20%-ban', 'eb']\n",
      "\n",
      "Strukturált adat: {'cat': 0.8, 'dog': 0.2, 'wild': 0.0}\n"
     ]
    }
   ],
   "source": [
    "structured = make_structured_data(tokens, threshold=0.8)\n",
    "\n",
    "print(f\"Bementi mondat: {input_sentence}\\n\")\n",
    "print(f\"Tokenek: {tokens}\\n\")\n",
    "print(f\"Strukturált adat: {structured}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
