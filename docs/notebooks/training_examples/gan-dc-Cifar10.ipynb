{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T09:36:51.664992Z",
     "iopub.status.busy": "2022-04-04T09:36:51.664389Z",
     "iopub.status.idle": "2022-04-04T09:36:55.747241Z",
     "shell.execute_reply": "2022-04-04T09:36:55.746469Z",
     "shell.execute_reply.started": "2022-04-04T09:36:51.664894Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T09:36:55.74933Z",
     "iopub.status.busy": "2022-04-04T09:36:55.749078Z",
     "iopub.status.idle": "2022-04-04T09:37:05.167794Z",
     "shell.execute_reply": "2022-04-04T09:37:05.167052Z",
     "shell.execute_reply.started": "2022-04-04T09:36:55.749296Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "number_of_examples = 16\n",
    "batch_size = 32\n",
    "latent_dim = 100\n",
    "image_size = (32, 32) # h x w\n",
    "\n",
    "seed = tf.random.normal([number_of_examples, latent_dim])\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = (x_train - 127.5) / 127.5 #Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T09:37:05.169378Z",
     "iopub.status.busy": "2022-04-04T09:37:05.169125Z",
     "iopub.status.idle": "2022-04-04T09:37:07.89724Z",
     "shell.execute_reply": "2022-04-04T09:37:07.89592Z",
     "shell.execute_reply.started": "2022-04-04T09:37:05.169345Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)\n",
    ").batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T09:37:07.903985Z",
     "iopub.status.busy": "2022-04-04T09:37:07.902023Z",
     "iopub.status.idle": "2022-04-04T09:37:07.919479Z",
     "shell.execute_reply": "2022-04-04T09:37:07.918832Z",
     "shell.execute_reply.started": "2022-04-04T09:37:07.903945Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model(latent_dim):\n",
    "    noise = keras.layers.Input(shape=[latent_dim])\n",
    "    \n",
    "    hidden = keras.layers.Reshape((1, 1, latent_dim))(noise)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(512, 4, 1, 'valid')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(256, 3, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(128, 3, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(3, 3, 2, 'same')(hidden)\n",
    "    out = keras.layers.Activation(\"tanh\")(hidden)\n",
    "    \n",
    "    return keras.Model(inputs=noise, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T09:37:07.921062Z",
     "iopub.status.busy": "2022-04-04T09:37:07.920789Z",
     "iopub.status.idle": "2022-04-04T09:37:14.704939Z",
     "shell.execute_reply": "2022-04-04T09:37:14.70397Z",
     "shell.execute_reply.started": "2022-04-04T09:37:07.921026Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model(latent_dim)\n",
    "\n",
    "noise = tf.random.normal([1, latent_dim])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow((generated_image[0].numpy()*127.5+127.5).astype(\"uint32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T09:37:36.357634Z",
     "iopub.status.busy": "2022-04-04T09:37:36.357104Z",
     "iopub.status.idle": "2022-04-04T09:37:36.367936Z",
     "shell.execute_reply": "2022-04-04T09:37:36.367187Z",
     "shell.execute_reply.started": "2022-04-04T09:37:36.357595Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    image = keras.layers.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(128, 4, 2, 'same')(image)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(256, 4, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(512, 4, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(100, 4, 1, 'valid')(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    hidden = keras.layers.Flatten()(hidden)\n",
    "\n",
    "    out = keras.layers.Dense(1)(hidden)\n",
    "    \n",
    "    return keras.Model(inputs=image, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-04T09:37:36.722503Z",
     "iopub.status.busy": "2022-04-04T09:37:36.72188Z",
     "iopub.status.idle": "2022-04-04T09:37:36.935442Z",
     "shell.execute_reply": "2022-04-04T09:37:36.934598Z",
     "shell.execute_reply.started": "2022-04-04T09:37:36.722466Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-04T09:37:14.721903Z",
     "iopub.status.idle": "2022-04-04T09:37:14.722943Z",
     "shell.execute_reply": "2022-04-04T09:37:14.722704Z",
     "shell.execute_reply.started": "2022-04-04T09:37:14.722679Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.constant(np.full(real_output.shape, 0.9)), real_output)\n",
    "    fake_loss = cross_entropy(tf.constant(np.full(fake_output.shape, 0)), fake_output)\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "discriminator_optimizer = keras.optimizers.Adam(4e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-04T09:37:14.724206Z",
     "iopub.status.idle": "2022-04-04T09:37:14.725099Z",
     "shell.execute_reply": "2022-04-04T09:37:14.72487Z",
     "shell.execute_reply.started": "2022-04-04T09:37:14.724829Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(\n",
    "        gen_loss,\n",
    "        generator.trainable_variables\n",
    "    )\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(\n",
    "        disc_loss,\n",
    "        discriminator.trainable_variables\n",
    "    )\n",
    "\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_generator,\n",
    "            generator.trainable_variables)\n",
    "        )\n",
    "    discriminator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_discriminator,\n",
    "            discriminator.trainable_variables)\n",
    "        )\n",
    "\n",
    "    return (gen_loss, disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-04T09:37:14.726403Z",
     "iopub.status.idle": "2022-04-04T09:37:14.727248Z",
     "shell.execute_reply": "2022-04-04T09:37:14.726871Z",
     "shell.execute_reply.started": "2022-04-04T09:37:14.726846Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"epochs\"):\n",
    "    os.mkdir(\"epochs\")\n",
    "\n",
    "def plot_grid_of_images(images, epoch):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((images[i].numpy() * 127.5 + 127.5).astype(\"uint32\"))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('epochs/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-04T09:37:14.728624Z",
     "iopub.status.idle": "2022-04-04T09:37:14.729287Z",
     "shell.execute_reply": "2022-04-04T09:37:14.729079Z",
     "shell.execute_reply.started": "2022-04-04T09:37:14.729054Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    generator_losses = np.empty((0, 0), dtype=float)\n",
    "    discriminator_losses = np.empty((0, 0), dtype=float)\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        batch_generator_losses = np.empty((0, 0), dtype=float)\n",
    "        batch_discriminator_losses = np.empty((0, 0), dtype=float)\n",
    "        for (batch, image_batch) in enumerate(dataset):\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "            \n",
    "            if batch % 500 == 0:\n",
    "                average_batch_loss =\\\n",
    "                   gen_loss.numpy()/int(image_batch[0].shape[1])\n",
    "                print(f\"\"\"Epoch {epoch+1}\n",
    "                        Batch {batch} Loss {average_batch_loss:.4f}\"\"\")\n",
    "\n",
    "            batch_generator_losses = np.append(batch_generator_losses, gen_loss)\n",
    "            batch_discriminator_losses = np.append(batch_discriminator_losses, disc_loss)\n",
    "        if generator_losses.shape == (0, 0):\n",
    "            generator_losses = batch_generator_losses\n",
    "            discriminator_losses = batch_discriminator_losses\n",
    "        else:\n",
    "            generator_losses = np.vstack(\n",
    "                [generator_losses, batch_generator_losses]\n",
    "            )\n",
    "            discriminator_losses = np.vstack(\n",
    "                [discriminator_losses, batch_discriminator_losses]\n",
    "            )\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "        example_images = generator((image_seed, label_seed), training=False)\n",
    "        plot_grid_of_images(example_images, epoch)\n",
    "    \n",
    "    return (generator_losses, discriminator_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-04T09:37:14.730508Z",
     "iopub.status.idle": "2022-04-04T09:37:14.731151Z",
     "shell.execute_reply": "2022-04-04T09:37:14.730917Z",
     "shell.execute_reply.started": "2022-04-04T09:37:14.730893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "(generator_losses, discriminator_losses) = train(dataset, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-04T09:37:14.732366Z",
     "iopub.status.idle": "2022-04-04T09:37:14.732976Z",
     "shell.execute_reply": "2022-04-04T09:37:14.732759Z",
     "shell.execute_reply.started": "2022-04-04T09:37:14.732736Z"
    }
   },
   "outputs": [],
   "source": [
    "gen = generator_losses[:epochs].mean(axis=1) / batch_size\n",
    "disc = discriminator_losses[:epochs].mean(axis=1) / batch_size\n",
    "\n",
    "fig_1 = plt.figure(figsize=(8, 4), dpi=100)\n",
    "ax = fig_1.add_axes([0, 0, 1, 1])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('DCGAN hibaértékei az első 50 epoch alatt')\n",
    "ax.plot(np.linspace(1, epochs, epochs), gen, label='Generator')\n",
    "ax.plot(np.linspace(1, epochs, epochs), disc, label='Discriminator')\n",
    "ax.legend(loc=0)\n",
    "\n",
    "ax.grid(True, color='0.6', dashes=(5, 2, 1, 2))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "\n",
    "x_ticks = np.arange(0, epochs+1, 5)\n",
    "x_ticks[0] = 1\n",
    "ax.set_xticks(x_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
