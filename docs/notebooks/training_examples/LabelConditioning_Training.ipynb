{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:16.222730Z",
     "iopub.status.busy": "2022-03-18T16:30:16.222386Z",
     "iopub.status.idle": "2022-03-18T16:30:16.228917Z",
     "shell.execute_reply": "2022-03-18T16:30:16.227910Z",
     "shell.execute_reply.started": "2022-03-18T16:30:16.222658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 10:26:04.280494: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-30 10:26:04.280531: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:16.232005Z",
     "iopub.status.busy": "2022-03-18T16:30:16.231338Z",
     "iopub.status.idle": "2022-03-18T16:30:16.245552Z",
     "shell.execute_reply": "2022-03-18T16:30:16.243932Z",
     "shell.execute_reply.started": "2022-03-18T16:30:16.231959Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "number_of_examples = 16\n",
    "batch_size = 128\n",
    "latent_dim = 100\n",
    "image_size = (32, 32) # h x w\n",
    "\n",
    "image_seed = tf.random.normal([number_of_examples, latent_dim])\n",
    "label_seed = tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5])\n",
    "\n",
    "number_of_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:16.248770Z",
     "iopub.status.busy": "2022-03-18T16:30:16.248227Z",
     "iopub.status.idle": "2022-03-18T16:30:17.757426Z",
     "shell.execute_reply": "2022-03-18T16:30:17.756435Z",
     "shell.execute_reply.started": "2022-03-18T16:30:16.248725Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = (x_train - 127.5) / 127.5 #Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:17.759377Z",
     "iopub.status.busy": "2022-03-18T16:30:17.758950Z",
     "iopub.status.idle": "2022-03-18T16:30:20.673871Z",
     "shell.execute_reply": "2022-03-18T16:30:20.672840Z",
     "shell.execute_reply.started": "2022-03-18T16:30:17.759322Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)\n",
    ").batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:20.679225Z",
     "iopub.status.busy": "2022-03-18T16:30:20.678982Z",
     "iopub.status.idle": "2022-03-18T16:30:20.692854Z",
     "shell.execute_reply": "2022-03-18T16:30:20.691730Z",
     "shell.execute_reply.started": "2022-03-18T16:30:20.679191Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model(latent_dim):\n",
    "    noise = keras.layers.Input(shape=[latent_dim])\n",
    "    label = keras.layers.Input(shape=(1, ))\n",
    "    \n",
    "    label_embedding = keras.layers.Flatten()(keras.layers.Embedding(number_of_classes, latent_dim)(label))\n",
    "    \n",
    "    gen_input = keras.layers.Multiply()([noise, label_embedding])\n",
    "    \n",
    "    hidden = keras.layers.Reshape((1, 1, latent_dim))(gen_input)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(512, 4, 1, 'valid')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(256, 4, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(128, 4, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(3, 4, 2, 'same')(hidden)\n",
    "    out = keras.layers.Activation(\"tanh\")(hidden)\n",
    "    \n",
    "    return keras.Model(inputs=[noise, label], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:20.695606Z",
     "iopub.status.busy": "2022-03-18T16:30:20.694912Z",
     "iopub.status.idle": "2022-03-18T16:30:20.841691Z",
     "shell.execute_reply": "2022-03-18T16:30:20.840655Z",
     "shell.execute_reply.started": "2022-03-18T16:30:20.695549Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:20.845268Z",
     "iopub.status.busy": "2022-03-18T16:30:20.845071Z",
     "iopub.status.idle": "2022-03-18T16:30:20.861718Z",
     "shell.execute_reply": "2022-03-18T16:30:20.859851Z",
     "shell.execute_reply.started": "2022-03-18T16:30:20.845242Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    image = keras.layers.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    label = keras.layers.Input(shape=(1, ))\n",
    "    \n",
    "    hidden = keras.layers.GaussianNoise(0.1)(image)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(128, 4, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(256, 4, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(512, 4, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(100, 4, 1, 'valid')(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    features = keras.layers.Flatten()(hidden)\n",
    "    \n",
    "    label_embedding = keras.layers.Flatten()(keras.layers.Embedding(number_of_classes, latent_dim)(label))\n",
    "    \n",
    "    embedded_space = keras.layers.Multiply()([features, label_embedding]) \n",
    "    \n",
    "    hidden = keras.layers.Dropout(0.3)(embedded_space)\n",
    "    \n",
    "    out = keras.layers.Dense(1)(hidden)\n",
    "    \n",
    "    return keras.Model(inputs=[image, label], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:20.864832Z",
     "iopub.status.busy": "2022-03-18T16:30:20.863924Z",
     "iopub.status.idle": "2022-03-18T16:30:20.986031Z",
     "shell.execute_reply": "2022-03-18T16:30:20.985076Z",
     "shell.execute_reply.started": "2022-03-18T16:30:20.864726Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:20.988069Z",
     "iopub.status.busy": "2022-03-18T16:30:20.987861Z",
     "iopub.status.idle": "2022-03-18T16:30:21.007116Z",
     "shell.execute_reply": "2022-03-18T16:30:21.006158Z",
     "shell.execute_reply.started": "2022-03-18T16:30:20.988029Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.constant(np.full(real_output.shape, 0.9)), real_output)\n",
    "    fake_loss = cross_entropy(tf.constant(np.full(fake_output.shape, 0)), fake_output)\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "discriminator_optimizer = keras.optimizers.Adam(4e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:21.009437Z",
     "iopub.status.busy": "2022-03-18T16:30:21.008861Z",
     "iopub.status.idle": "2022-03-18T16:30:21.057486Z",
     "shell.execute_reply": "2022-03-18T16:30:21.056457Z",
     "shell.execute_reply.started": "2022-03-18T16:30:21.009398Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    train_images, train_labels = images\n",
    "    \n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator((noise, train_labels), training=True)\n",
    "\n",
    "        real_output = discriminator((train_images, train_labels), training=True)\n",
    "        fake_output = discriminator((generated_images, train_labels), training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(\n",
    "        gen_loss,\n",
    "        generator.trainable_variables\n",
    "    )\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(\n",
    "        disc_loss,\n",
    "        discriminator.trainable_variables\n",
    "    )\n",
    "\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_generator,\n",
    "            generator.trainable_variables)\n",
    "        )\n",
    "    discriminator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_discriminator,\n",
    "            discriminator.trainable_variables)\n",
    "        )\n",
    "\n",
    "    return (gen_loss, disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:21.062623Z",
     "iopub.status.busy": "2022-03-18T16:30:21.062394Z",
     "iopub.status.idle": "2022-03-18T16:30:21.069155Z",
     "shell.execute_reply": "2022-03-18T16:30:21.067958Z",
     "shell.execute_reply.started": "2022-03-18T16:30:21.062580Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_grid_of_images(images, epoch):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((images[i].numpy() * 127.5 + 127.5).astype(\"uint32\"))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:21.072345Z",
     "iopub.status.busy": "2022-03-18T16:30:21.071324Z",
     "iopub.status.idle": "2022-03-18T16:30:21.087957Z",
     "shell.execute_reply": "2022-03-18T16:30:21.086606Z",
     "shell.execute_reply.started": "2022-03-18T16:30:21.072061Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    generator_losses = np.empty((0, 0), dtype=float)\n",
    "    discriminator_losses = np.empty((0, 0), dtype=float)\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        batch_generator_losses = np.empty((0, 0), dtype=float)\n",
    "        batch_discriminator_losses = np.empty((0, 0), dtype=float)\n",
    "        for (batch, image_batch) in enumerate(dataset):\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "            \n",
    "            if batch % 500 == 0:\n",
    "                average_batch_loss =\\\n",
    "                   gen_loss.numpy()/int(image_batch[0].shape[1])\n",
    "                print(f\"\"\"Epoch {epoch+1}\n",
    "                        Batch {batch} Loss {average_batch_loss:.4f}\"\"\")\n",
    "\n",
    "            batch_generator_losses = np.append(batch_generator_losses, gen_loss)\n",
    "            batch_discriminator_losses = np.append(batch_discriminator_losses, disc_loss)\n",
    "        if generator_losses.shape == (0, 0):\n",
    "            generator_losses = batch_generator_losses\n",
    "            discriminator_losses = batch_discriminator_losses\n",
    "        else:\n",
    "            generator_losses = np.vstack(\n",
    "                [generator_losses, batch_generator_losses]\n",
    "            )\n",
    "            discriminator_losses = np.vstack(\n",
    "                [discriminator_losses, batch_discriminator_losses]\n",
    "            )\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "        example_images = generator((image_seed, label_seed), training=False)\n",
    "        plot_grid_of_images(example_images, epoch)\n",
    "    \n",
    "    return (generator_losses, discriminator_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:30:21.092440Z",
     "iopub.status.busy": "2022-03-18T16:30:21.091971Z",
     "iopub.status.idle": "2022-03-18T16:50:03.470410Z",
     "shell.execute_reply": "2022-03-18T16:50:03.469551Z",
     "shell.execute_reply.started": "2022-03-18T16:30:21.092407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "(generator_losses, discriminator_losses) = train(dataset, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:53:37.985214Z",
     "iopub.status.busy": "2022-03-18T16:53:37.984953Z",
     "iopub.status.idle": "2022-03-18T16:53:46.310439Z",
     "shell.execute_reply": "2022-03-18T16:53:46.309608Z",
     "shell.execute_reply.started": "2022-03-18T16:53:37.985185Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "noises = tf.random.normal([number_of_examples, latent_dim])\n",
    "for i in range(10):\n",
    "    print(class_names[i])\n",
    "    \n",
    "    example_images = generator((noises, tf.constant(np.full(16, i))), training=False)\n",
    "    plot_grid_of_images(example_images, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T16:54:51.955173Z",
     "iopub.status.busy": "2022-03-18T16:54:51.954874Z",
     "iopub.status.idle": "2022-03-18T16:54:52.016361Z",
     "shell.execute_reply": "2022-03-18T16:54:52.015367Z",
     "shell.execute_reply.started": "2022-03-18T16:54:51.955143Z"
    }
   },
   "outputs": [],
   "source": [
    "generator.save(\"generatorcifar10.h5\")\n",
    "discriminator.save(\"discriminatorcifar10.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
