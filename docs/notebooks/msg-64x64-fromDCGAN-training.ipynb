{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:23:31.267984Z",
     "iopub.status.busy": "2022-02-25T13:23:31.267730Z",
     "iopub.status.idle": "2022-02-25T13:23:31.276266Z",
     "shell.execute_reply": "2022-02-25T13:23:31.275469Z",
     "shell.execute_reply.started": "2022-02-25T13:23:31.267955Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from tensorflow import random\n",
    "from tensorflow import GradientTape\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:23:31.710591Z",
     "iopub.status.busy": "2022-02-25T13:23:31.710324Z",
     "iopub.status.idle": "2022-02-25T13:23:41.554900Z",
     "shell.execute_reply": "2022-02-25T13:23:41.553350Z",
     "shell.execute_reply.started": "2022-02-25T13:23:31.710557Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "number_of_examples = 8\n",
    "batch_size = 16\n",
    "latent_dim = 100\n",
    "image_size = (64, 64) # h x w\n",
    "\n",
    "seed = tf.random.normal([number_of_examples, latent_dim])\n",
    "\n",
    "data_dir = r'../input/animal-faces/afhq/train/'\n",
    "\n",
    "dataset = image_dataset_from_directory(\n",
    "    data_dir, label_mode=None, image_size=image_size, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:23:47.016236Z",
     "iopub.status.busy": "2022-02-25T13:23:47.015972Z",
     "iopub.status.idle": "2022-02-25T13:23:47.040403Z",
     "shell.execute_reply": "2022-02-25T13:23:47.039771Z",
     "shell.execute_reply.started": "2022-02-25T13:23:47.016207Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: (x - 127.5) / 127.5) # Normalizing to -1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:21.218353Z",
     "iopub.status.busy": "2022-02-25T13:37:21.218094Z",
     "iopub.status.idle": "2022-02-25T13:37:21.230757Z",
     "shell.execute_reply": "2022-02-25T13:37:21.230077Z",
     "shell.execute_reply.started": "2022-02-25T13:37:21.218323Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model(latent_dim):\n",
    "    visible = Input(shape=[latent_dim])\n",
    "    hidden = Reshape((1, 1, 100))(visible)\n",
    "\n",
    "    hidden = Conv2DTranspose(filters=512, kernel_size=4, strides=(1, 1),\n",
    "                             padding='valid', activation=\"relu\")(hidden)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "    out4x4 = hidden\n",
    "    out4x4 = Conv2D(filters=3, kernel_size=4, strides=(1, 1), padding='same')(out4x4)\n",
    "    out4x4 = Activation(\"tanh\")(out4x4)\n",
    "\n",
    "\n",
    "    hidden = Conv2DTranspose(filters=256, kernel_size=4, strides=(2, 2),\n",
    "                             padding='same', activation=\"relu\")(hidden)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "    out8x8 = hidden\n",
    "    out8x8 = Conv2D(filters=3, kernel_size=4, strides=(1, 1), padding='same')(out8x8)\n",
    "    out8x8 = Activation(\"tanh\")(out8x8)\n",
    "\n",
    "\n",
    "    hidden = Conv2DTranspose(filters=128, kernel_size=4, strides=(2, 2),\n",
    "                             padding='same', activation=\"relu\")(hidden)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "    out16x16 = hidden\n",
    "    out16x16 = Conv2D(filters=3, kernel_size=4, strides=(1, 1), padding='same')(out16x16)\n",
    "    out16x16 = Activation(\"tanh\")(out16x16)\n",
    "\n",
    "\n",
    "    hidden = Conv2DTranspose(filters=64, kernel_size=4, strides=(2, 2),\n",
    "                             padding='same', activation=\"relu\")(hidden)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "    out32x32 = hidden\n",
    "    out32x32 = Conv2D(filters=3, kernel_size=4, strides=(1, 1), padding='same')(out32x32)\n",
    "    out32x32 = Activation(\"tanh\")(out32x32)\n",
    "\n",
    "\n",
    "    hidden = Conv2DTranspose(filters=64, kernel_size=4, strides=(2, 2),\n",
    "                             padding='same', activation=\"relu\")(hidden)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "    hidden = Conv2D(filters=3, kernel_size=4, strides=(1, 1), padding='same')(hidden)\n",
    "    out64x64 = Activation(\"tanh\")(hidden)\n",
    "    model = Model(inputs=visible, outputs=[out64x64, out32x32, out16x16, out8x8, out4x4])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:21.649787Z",
     "iopub.status.busy": "2022-02-25T13:37:21.648879Z",
     "iopub.status.idle": "2022-02-25T13:37:21.988625Z",
     "shell.execute_reply": "2022-02-25T13:37:21.987909Z",
     "shell.execute_reply.started": "2022-02-25T13:37:21.649738Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model(latent_dim)\n",
    "\n",
    "noise = tf.random.normal([1, latent_dim])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow((generated_image[0][0].numpy()*127.5+127.5).astype(\"uint32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:22.671047Z",
     "iopub.status.busy": "2022-02-25T13:37:22.670397Z",
     "iopub.status.idle": "2022-02-25T13:37:22.683474Z",
     "shell.execute_reply": "2022-02-25T13:37:22.682601Z",
     "shell.execute_reply.started": "2022-02-25T13:37:22.671007Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    input1 = Input(shape=(64, 64, 3))\n",
    "    hidden = Conv2D(filters=64, kernel_size=4, strides=2, padding=\"same\",\n",
    "                    activation=\"relu\", kernel_initializer=\"he_normal\")(input1)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "\n",
    "    input2 = Input(shape=(32, 32, 3))\n",
    "    hidden = Concatenate()([hidden, input2])\n",
    "    hidden = Conv2D(filters=128, kernel_size=4, strides=2, padding=\"same\",\n",
    "                    activation=\"relu\", kernel_initializer=\"he_normal\")(hidden)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "\n",
    "    input3 = Input(shape=(16, 16, 3))\n",
    "    hidden = Concatenate()([hidden, input3])\n",
    "    hidden = Conv2D(filters=256, kernel_size=4, strides=2, padding=\"same\",\n",
    "                    activation=\"relu\", kernel_initializer=\"he_normal\")(hidden)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "\n",
    "    input4 = Input(shape=(8, 8, 3))\n",
    "    hidden = Concatenate()([hidden, input4])\n",
    "    hidden = Conv2D(filters=512, kernel_size=4, strides=2, padding=\"same\",\n",
    "                    activation=\"relu\", kernel_initializer=\"he_normal\")(hidden)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "\n",
    "    input5 = Input(shape=(4, 4, 3))\n",
    "    hidden = Concatenate()([hidden, input5])\n",
    "\n",
    "    hidden = Conv2D(filters=1, kernel_size=4, strides=1, padding=\"valid\")(hidden)\n",
    "    hidden = Flatten()(hidden)\n",
    "    out = Activation(\"sigmoid\")(hidden)\n",
    "\n",
    "    model = Model(inputs=[input1, input2, input3, input4, input5], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:22.999476Z",
     "iopub.status.busy": "2022-02-25T13:37:22.999238Z",
     "iopub.status.idle": "2022-02-25T13:37:23.095635Z",
     "shell.execute_reply": "2022-02-25T13:37:23.094846Z",
     "shell.execute_reply.started": "2022-02-25T13:37:22.999448Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image, training=False)\n",
    "print(decision)\n",
    "generated_image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:23.650345Z",
     "iopub.status.busy": "2022-02-25T13:37:23.649681Z",
     "iopub.status.idle": "2022-02-25T13:37:23.656724Z",
     "shell.execute_reply": "2022-02-25T13:37:23.656033Z",
     "shell.execute_reply.started": "2022-02-25T13:37:23.650311Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"epochs\"):\n",
    "    os.mkdir(\"epochs\")\n",
    "def plot_examples(images_at_scales, epoch):\n",
    "    n_examples = images_at_scales[0].shape[0]\n",
    "    fig, axes = plt.subplots(figsize=(5, n_examples), nrows=n_examples, ncols=5, dpi=100)\n",
    "    for i in range(n_examples):\n",
    "        for j in range(5):\n",
    "            generated_images = images_at_scales[4-j]\n",
    "            gen_1 = generated_images[i].numpy()*127.5+127.5\n",
    "            axes[i, j].axis('off')\n",
    "            axes[i, j].imshow((gen_1).astype(\"uint32\"), interpolation='none')\n",
    "    plt.savefig('epochs/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:24.067819Z",
     "iopub.status.busy": "2022-02-25T13:37:24.067601Z",
     "iopub.status.idle": "2022-02-25T13:37:24.073333Z",
     "shell.execute_reply": "2022-02-25T13:37:24.072409Z",
     "shell.execute_reply.started": "2022-02-25T13:37:24.067794Z"
    }
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# The generator is performing well, if the discriminator classifies fakes as real(1)\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:24.469860Z",
     "iopub.status.busy": "2022-02-25T13:37:24.469280Z",
     "iopub.status.idle": "2022-02-25T13:37:24.475042Z",
     "shell.execute_reply": "2022-02-25T13:37:24.473898Z",
     "shell.execute_reply.started": "2022-02-25T13:37:24.469820Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:24.845970Z",
     "iopub.status.busy": "2022-02-25T13:37:24.845757Z",
     "iopub.status.idle": "2022-02-25T13:37:24.856405Z",
     "shell.execute_reply": "2022-02-25T13:37:24.855711Z",
     "shell.execute_reply.started": "2022-02-25T13:37:24.845945Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:25.209037Z",
     "iopub.status.busy": "2022-02-25T13:37:25.208672Z",
     "iopub.status.idle": "2022-02-25T13:37:25.263178Z",
     "shell.execute_reply": "2022-02-25T13:37:25.262527Z",
     "shell.execute_reply.started": "2022-02-25T13:37:25.209007Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with GradientTape() as gen_tape, GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(\n",
    "        gen_loss,\n",
    "        generator.trainable_variables\n",
    "    )\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(\n",
    "        disc_loss,\n",
    "        discriminator.trainable_variables\n",
    "    )\n",
    "\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_generator,\n",
    "            generator.trainable_variables)\n",
    "        )\n",
    "    discriminator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_discriminator,\n",
    "            discriminator.trainable_variables)\n",
    "        )\n",
    "\n",
    "    return (gen_loss, disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:25.608139Z",
     "iopub.status.busy": "2022-02-25T13:37:25.607586Z",
     "iopub.status.idle": "2022-02-25T13:37:25.612974Z",
     "shell.execute_reply": "2022-02-25T13:37:25.612328Z",
     "shell.execute_reply.started": "2022-02-25T13:37:25.608109Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_input_images(image_batch):\n",
    "    result = []\n",
    "    result.append(image_batch)\n",
    "    result.append(tf.image.resize(image_batch, [32, 32]))\n",
    "    result.append(tf.image.resize(image_batch, [16, 16]))\n",
    "    result.append(tf.image.resize(image_batch, [8, 8]))\n",
    "    result.append(tf.image.resize(image_batch, [4, 4]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T13:37:25.980432Z",
     "iopub.status.busy": "2022-02-25T13:37:25.979806Z",
     "iopub.status.idle": "2022-02-25T13:37:25.992211Z",
     "shell.execute_reply": "2022-02-25T13:37:25.991447Z",
     "shell.execute_reply.started": "2022-02-25T13:37:25.980394Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    generator_losses = np.empty((0, 0), dtype=float)\n",
    "    discriminator_losses = np.empty((0, 0), dtype=float)\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        batch_generator_losses = np.empty((0, 0), dtype=float)\n",
    "        batch_discriminator_losses = np.empty((0, 0), dtype=float)\n",
    "        for (batch, image_batch) in enumerate(dataset):\n",
    "            scaled_batch = scale_input_images(image_batch)\n",
    "            gen_loss, disc_loss = train_step(scaled_batch)\n",
    "            \n",
    "            if batch % 100 == 0:\n",
    "                average_batch_loss =\\\n",
    "                   gen_loss.numpy()/int(image_batch.shape[1])\n",
    "                print(f\"\"\"Epoch {epoch+1}\n",
    "                        Batch {batch} Loss {average_batch_loss:.4f}\"\"\")\n",
    "\n",
    "            batch_generator_losses = np.append(batch_generator_losses, gen_loss)\n",
    "            batch_discriminator_losses = np.append(batch_discriminator_losses, disc_loss)\n",
    "            \n",
    "        if generator_losses.shape == (0, 0):\n",
    "            generator_losses = batch_generator_losses\n",
    "            discriminator_losses = batch_discriminator_losses\n",
    "        else:\n",
    "            generator_losses = np.vstack(\n",
    "                [generator_losses, batch_generator_losses]\n",
    "            )\n",
    "            discriminator_losses = np.vstack(\n",
    "                [discriminator_losses, batch_discriminator_losses]\n",
    "            )\n",
    "            \n",
    "        # Saving the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "            \n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "        # Producing images for the GIF\n",
    "        #display.clear_output(wait=True)\n",
    "        example_images = generator(seed, training=False)\n",
    "        plot_examples(example_images, epoch)\n",
    "        \n",
    "\n",
    "    # Generating after the final epoch\n",
    "    example_images = generator(seed, training=False)\n",
    "    plot_examples(example_images, epoch)\n",
    "    \n",
    "    return (generator_losses, discriminator_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T14:35:36.923217Z",
     "iopub.status.busy": "2022-02-25T14:35:36.922957Z",
     "iopub.status.idle": "2022-02-25T15:06:14.426315Z",
     "shell.execute_reply": "2022-02-25T15:06:14.425421Z",
     "shell.execute_reply.started": "2022-02-25T14:35:36.923186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "(generator_losses, discriminator_losses) = train(dataset, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T15:06:37.318067Z",
     "iopub.status.busy": "2022-02-25T15:06:37.317775Z",
     "iopub.status.idle": "2022-02-25T15:06:37.608139Z",
     "shell.execute_reply": "2022-02-25T15:06:37.607360Z",
     "shell.execute_reply.started": "2022-02-25T15:06:37.318026Z"
    }
   },
   "outputs": [],
   "source": [
    "gen = generator_losses[:epochs].mean(axis=1) / batch_size\n",
    "disc = discriminator_losses[:epochs].mean(axis=1) / batch_size\n",
    "\n",
    "fig_1 = plt.figure(figsize=(8, 4), dpi=100)\n",
    "ax = fig_1.add_axes([0, 0, 1, 1])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('DCGAN hibaértékei az első 50 epoch alatt')\n",
    "ax.plot(np.linspace(1, epochs, epochs), gen, label='Generator')\n",
    "ax.plot(np.linspace(1, epochs, epochs), disc, label='Discriminator')\n",
    "ax.legend(loc=0)\n",
    "\n",
    "ax.grid(True, color='0.6', dashes=(5, 2, 1, 2))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "\n",
    "x_ticks = np.arange(0, epochs+1, 5)\n",
    "x_ticks[0] = 1\n",
    "ax.set_xticks(x_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T15:11:20.907500Z",
     "iopub.status.busy": "2022-02-25T15:11:20.907252Z",
     "iopub.status.idle": "2022-02-25T15:11:23.906973Z",
     "shell.execute_reply": "2022-02-25T15:11:23.906375Z",
     "shell.execute_reply.started": "2022-02-25T15:11:20.907471Z"
    }
   },
   "outputs": [],
   "source": [
    "noises = random.normal([16, latent_dim])\n",
    "example_images = generator(noises, training=False)\n",
    "\n",
    "plt.imshow((example_images[0][0].numpy()*127.5+127.5).astype(\"uint32\"), interpolation='none')\n",
    "plot_examples(example_images, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T15:10:36.847124Z",
     "iopub.status.busy": "2022-02-25T15:10:36.846442Z",
     "iopub.status.idle": "2022-02-25T15:10:37.034440Z",
     "shell.execute_reply": "2022-02-25T15:10:37.033807Z",
     "shell.execute_reply.started": "2022-02-25T15:10:36.847089Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
