{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import UpSampling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense\n\nfrom tensorflow import random\nfrom tensorflow import GradientTape\n\n\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nimport time\n\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:35.700876Z","iopub.execute_input":"2022-02-28T10:17:35.701131Z","iopub.status.idle":"2022-02-28T10:17:35.711659Z","shell.execute_reply.started":"2022-02-28T10:17:35.701102Z","shell.execute_reply":"2022-02-28T10:17:35.710952Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nnumber_of_examples = 16\nbatch_size = 16\nlatent_dim = 512\nimage_size = (64, 64) # h x w\nnum_examples_to_generate = 16\n\ndata_dir = r'../input/animal-faces/afhq/train/'\n\ndataset = image_dataset_from_directory(\n    data_dir, label_mode=None, image_size=image_size, batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:35.713749Z","iopub.execute_input":"2022-02-28T10:17:35.714094Z","iopub.status.idle":"2022-02-28T10:17:37.110266Z","shell.execute_reply.started":"2022-02-28T10:17:35.714056Z","shell.execute_reply":"2022-02-28T10:17:37.109527Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(lambda x: (x - 127.5) / 127.5) # Normalizing to -1,1","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.111559Z","iopub.execute_input":"2022-02-28T10:17:37.111978Z","iopub.status.idle":"2022-02-28T10:17:37.134245Z","shell.execute_reply.started":"2022-02-28T10:17:37.111941Z","shell.execute_reply":"2022-02-28T10:17:37.133602Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"def make_generator_model(latent_dim):\n    visible = Input(shape=[latent_dim])\n    hidden = Reshape((1, 1, latent_dim))(visible)\n\n    hidden = Conv2DTranspose(filters=512, kernel_size=4, strides=(1, 1),\n                             padding='valid', activation=\"leaky_relu\")(hidden)\n\n    hidden = Conv2DTranspose(filters=256, kernel_size=3, strides=(2, 2),\n                             padding='same', activation=\"leaky_relu\")(hidden)\n    # hidden = BatchNormalization()(hidden)\n    hidden = Conv2DTranspose(filters=128, kernel_size=3, strides=(2, 2),\n                             padding='same', activation=\"leaky_relu\")(hidden)\n    # hidden = BatchNormalization()(hidden)\n    hidden = Conv2DTranspose(filters=64, kernel_size=3, strides=(2, 2),\n                             padding='same', activation=\"leaky_relu\")(hidden)\n    # hidden = BatchNormalization()(hidden)\n    hidden = Conv2DTranspose(filters=32, kernel_size=3, strides=(2, 2),\n                             padding='same', activation=\"leaky_relu\")(hidden)\n    # hidden = BatchNormalization()(hidden)\n    \n    out4x4 = hidden\n    out4x4 = Conv2D(filters=3, kernel_size=4, strides=(1, 1), padding='same')(out4x4) # ToRGB\n    out4x4 = Activation(\"tanh\")(out4x4)\n\n    model = Model(inputs=visible, outputs=[out4x4])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.135492Z","iopub.execute_input":"2022-02-28T10:17:37.135737Z","iopub.status.idle":"2022-02-28T10:17:37.146333Z","shell.execute_reply.started":"2022-02-28T10:17:37.135704Z","shell.execute_reply":"2022-02-28T10:17:37.145608Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"generator = make_generator_model(latent_dim)\n\nnoise = tf.random.normal([1, latent_dim])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow((generated_image[0].numpy()*127.5+127.5).astype(\"uint32\"))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.149907Z","iopub.execute_input":"2022-02-28T10:17:37.150089Z","iopub.status.idle":"2022-02-28T10:17:37.418033Z","shell.execute_reply.started":"2022-02-28T10:17:37.150067Z","shell.execute_reply":"2022-02-28T10:17:37.417321Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"def make_discriminator_model():\n    input5 = Input(shape=(64, 64, 3))\n    hidden = Conv2D(filters=32, kernel_size=4, strides=1, padding=\"same\",\n                    activation=\"leaky_relu\")(input5) # From RGB\n    \n    hidden = Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\",\n                    activation=\"leaky_relu\")(hidden)\n    # hidden = BatchNormalization()(hidden)\n    \n    hidden = Conv2D(filters=128, kernel_size=3, strides=2, padding=\"same\",\n                    activation=\"leaky_relu\")(hidden)\n    # hidden = BatchNormalization()(hidden)\n    \n    hidden = Conv2D(filters=256, kernel_size=3, strides=2, padding=\"same\",\n                    activation=\"leaky_relu\")(hidden)\n    # hidden = BatchNormalization()(hidden)\n    \n    hidden = Conv2D(filters=512, kernel_size=3, strides=2, padding=\"same\",\n                    activation=\"leaky_relu\")(hidden)\n    # hidden = BatchNormalization()(hidden)\n    \n    hidden = Conv2D(filters=512, kernel_size=4, strides=1, padding=\"valid\", activation=\"leaky_relu\")(hidden)\n    hidden = Flatten()(hidden)\n    hidden = Dense(1)(hidden)\n    out = Activation(\"sigmoid\")(hidden)\n\n    model = Model(inputs=[input5], outputs=[out])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.419242Z","iopub.execute_input":"2022-02-28T10:17:37.419664Z","iopub.status.idle":"2022-02-28T10:17:37.428819Z","shell.execute_reply.started":"2022-02-28T10:17:37.419632Z","shell.execute_reply":"2022-02-28T10:17:37.428165Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_image)\nprint(decision)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.430153Z","iopub.execute_input":"2022-02-28T10:17:37.430626Z","iopub.status.idle":"2022-02-28T10:17:37.708837Z","shell.execute_reply.started":"2022-02-28T10:17:37.430589Z","shell.execute_reply":"2022-02-28T10:17:37.707329Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    \n    total_loss = real_loss + fake_loss\n    return total_loss\n\n# The generator is performing well, if the discriminator classifies fakes as real(1)\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.711558Z","iopub.execute_input":"2022-02-28T10:17:37.712172Z","iopub.status.idle":"2022-02-28T10:17:37.718143Z","shell.execute_reply.started":"2022-02-28T10:17:37.712132Z","shell.execute_reply":"2022-02-28T10:17:37.717359Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.719478Z","iopub.execute_input":"2022-02-28T10:17:37.719981Z","iopub.status.idle":"2022-02-28T10:17:37.727395Z","shell.execute_reply.started":"2022-02-28T10:17:37.719937Z","shell.execute_reply":"2022-02-28T10:17:37.726724Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.730376Z","iopub.execute_input":"2022-02-28T10:17:37.730622Z","iopub.status.idle":"2022-02-28T10:17:37.741048Z","shell.execute_reply.started":"2022-02-28T10:17:37.730599Z","shell.execute_reply":"2022-02-28T10:17:37.740293Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"seed = tf.random.normal([num_examples_to_generate, latent_dim])","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.744194Z","iopub.execute_input":"2022-02-28T10:17:37.744425Z","iopub.status.idle":"2022-02-28T10:17:37.748985Z","shell.execute_reply.started":"2022-02-28T10:17:37.744393Z","shell.execute_reply":"2022-02-28T10:17:37.748214Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(images):\n    noise = random.normal([batch_size, latent_dim])\n\n    with GradientTape() as gen_tape, GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(\n        gen_loss,\n        generator.trainable_variables\n    )\n\n    gradients_of_discriminator = disc_tape.gradient(\n        disc_loss,\n        discriminator.trainable_variables\n    )\n\n    generator_optimizer.apply_gradients(\n        zip(gradients_of_generator,\n            generator.trainable_variables)\n        )\n    discriminator_optimizer.apply_gradients(\n        zip(gradients_of_discriminator,\n            discriminator.trainable_variables)\n        )\n\n    return (gen_loss, disc_loss)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.750317Z","iopub.execute_input":"2022-02-28T10:17:37.750566Z","iopub.status.idle":"2022-02-28T10:17:37.794968Z","shell.execute_reply.started":"2022-02-28T10:17:37.750532Z","shell.execute_reply":"2022-02-28T10:17:37.794243Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"if not os.path.isdir(\"epochs\"):\n    os.mkdir(\"epochs\")\n\ndef plot_grid_of_images(images, epoch):\n    plt.figure(figsize=(8, 8))\n\n    for i in range(images.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow((images[i].numpy() * 127.5 + 127.5).astype(\"uint32\"))\n        plt.axis('off')\n\n    plt.savefig('epochs/image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.799207Z","iopub.execute_input":"2022-02-28T10:17:37.799432Z","iopub.status.idle":"2022-02-28T10:17:37.805406Z","shell.execute_reply.started":"2022-02-28T10:17:37.799405Z","shell.execute_reply":"2022-02-28T10:17:37.804498Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"def train(dataset, epochs):\n    generator_losses = np.empty((0, 0), dtype=float)\n    discriminator_losses = np.empty((0, 0), dtype=float)\n    for epoch in range(epochs):\n        start = time.time()\n        \n        batch_generator_losses = np.empty((0, 0), dtype=float)\n        batch_discriminator_losses = np.empty((0, 0), dtype=float)\n        for (batch, image_batch) in enumerate(dataset):\n            gen_loss, disc_loss = train_step(image_batch)\n            \n            if batch % 100 == 0:\n                average_batch_loss =\\\n                   gen_loss.numpy()/int(image_batch.shape[1])\n                print(f\"\"\"Epoch {epoch+1}\n                        Batch {batch} Loss {average_batch_loss:.4f}\"\"\")\n\n            batch_generator_losses = np.append(batch_generator_losses, gen_loss)\n            batch_discriminator_losses = np.append(batch_discriminator_losses, disc_loss)\n            \n        if generator_losses.shape == (0, 0):\n            generator_losses = batch_generator_losses\n            discriminator_losses = batch_discriminator_losses\n        else:\n            generator_losses = np.vstack(\n                [generator_losses, batch_generator_losses]\n            )\n            discriminator_losses = np.vstack(\n                [discriminator_losses, batch_discriminator_losses]\n            )\n            \n        # Saving the model every 15 epochs\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix = checkpoint_prefix)\n            \n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n        # Producing images for the GIF\n        #display.clear_output(wait=True)\n        example_images = generator(seed, training=False)\n        plot_grid_of_images(example_images, epoch)\n        \n\n    # Generating after the final epoch\n    example_images = generator(seed, training=False)\n    plot_grid_of_images(example_images, epoch)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.808831Z","iopub.execute_input":"2022-02-28T10:17:37.809129Z","iopub.status.idle":"2022-02-28T10:17:37.821395Z","shell.execute_reply.started":"2022-02-28T10:17:37.809091Z","shell.execute_reply":"2022-02-28T10:17:37.820625Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# Training the model\ntrain(dataset, epochs)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:17:37.822796Z","iopub.execute_input":"2022-02-28T10:17:37.823053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}