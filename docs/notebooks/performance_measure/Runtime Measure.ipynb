{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c4f10a",
   "metadata": {},
   "source": [
    "# Teljesítménymérés\n",
    "\n",
    "Ezen notebook célja olyan mérések elvégzése, amelyek során azt vizsgáljuk, hogy különböző paraméterek mellett hogyan változik a tanítás hossza.\n",
    "\n",
    "A méréshez használt dataset a cifar10, amely 50000 darab 32x32 méretű színes képből álló tanítóhalmazzal és 10000 elemszámú teszthalmazzal rendelkezik. A képekhez tartozik címke is, amelyből 10 féle van a datasetben.\n",
    "\n",
    "Mivel csupán mérések elvégzése a cél, így a 32x32-es maximális felbontás ebben a kísérletben elegendő lesz.\n",
    "A tanítást az 50000 kép egy részén is el lehetne végezni, mert a saját gépen az lehet sok lenne...)\n",
    "\n",
    "Paraméterek:\n",
    "\n",
    "- Felbontás: 4x4, 8x8, 16x16, 32x32 (A felbontás növelésével nő a rejtett rétegek száma is...)\n",
    "- Unitok száma: 64, 128, 256, 512\n",
    "- Kernelméret: 2x2, 3x3, 4x4, 5x5\n",
    "- Látens dimenzió: 64, 128, 256, 512\n",
    "- batch-size: 8, 16, 32, 64 ?\n",
    "- @tf.function vs sima function meghatározott paraméterek mellett, pl a felbontást növelve\n",
    "\n",
    "Az időméréshez a python3 `time` modulját használom fel, így a tényleges eltelt idő kerül meghatározásra (Wall time), nem a processzidő. Tanítás 3-5 epoch-ig, majd egy átlagos időt nézni, hogy mennyi jött ki.\n",
    "\n",
    "TODO: Mérés előkészítése, majd a kapott eredmények plotolása (előtte lehet jobb lenne csak lementeni file-ba, majd úgy plotolni)\n",
    "TODO: Futtatás Kaggle-ön és a saját gépemen\n",
    "- 4 -> 0\n",
    "- 8 -> 1\n",
    "- 16-> 2\n",
    "- 32-> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7826ba6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 19:13:04.420035: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-20 19:13:04.420081: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16571165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model(latent_dim, units_per_layer, upsampling_layers, kernel_size):\n",
    "    noise = keras.layers.Input(shape=[latent_dim])\n",
    "    hidden = keras.layers.Reshape((1, 1, latent_dim))(noise)\n",
    "\n",
    "    hidden = keras.layers.Conv2DTranspose(units_per_layer, 4, 1, 'valid')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization()(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    for i in range(upsampling_layers):\n",
    "        hidden = keras.layers.Conv2DTranspose(units_per_layer, kernel_size, 2, 'same')(hidden)\n",
    "        hidden = keras.layers.BatchNormalization()(hidden)\n",
    "        hidden = keras.layers.ReLU()(hidden)\n",
    "\n",
    "    hidden = keras.layers.Conv2D(3, kernel_size, 1, 'same')(hidden)\n",
    "    out = keras.layers.Activation(\"tanh\")(hidden)\n",
    "    \n",
    "    return keras.Model(inputs=noise, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa6a63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model(input_shape, latent_dim, units_per_layer, downsampling_layers, kernel_size):\n",
    "    image = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    hidden = keras.layers.Conv2D(units_per_layer, kernel_size, 1, 'same')(image)\n",
    "    hidden = keras.layers.BatchNormalization()(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    for i in range(downsampling_layers):\n",
    "        hidden = keras.layers.Conv2D(units_per_layer, kernel_size, 2, 'same')(hidden)\n",
    "        hidden = keras.layers.BatchNormalization()(hidden)\n",
    "        hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(latent_dim, 4, 1, 'valid')(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Flatten()(hidden)\n",
    "    out = keras.layers.Dense(1)(hidden)\n",
    "    \n",
    "    return keras.Model(inputs=image, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3f63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "discriminator_optimizer = keras.optimizers.Adam(4e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c66f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(generator, discriminator, images):    \n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return (gen_loss, disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a06eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, dataset, epochs):\n",
    "    avg_runtime = 0\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for (batch, image_batch) in enumerate(dataset): \n",
    "            gen_loss, disc_loss = trainn_step(generator, discriminator, image_batch)\n",
    "\n",
    "        epoch_runtime = time.time() - start\n",
    "        avg_runtime += epoch_runtime\n",
    "    return avg_runtime/epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1b075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(image_size, batch_size):\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "    x_train = tf.image.resize(x_train, image_size)\n",
    "    x_train = (x_train - 127.5) / 127.5 #Normalizing\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        x_train\n",
    "    ).batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e745e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 19:13:10.235402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-20 19:13:10.235442: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-20 19:13:10.235474: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Inspiron-5558): /proc/driver/nvidia/version does not exist\n",
      "2022-03-20 19:13:10.235875: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-20 19:13:10.778865: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600000 exceeds 10% of free system memory.\n",
      "2022-03-20 19:13:12.750634: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (4, 4) with 0 resizing layers, Average runtime: 23.508806467056274 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 19:15:10.352717: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (8, 8) with 1 resizing layers, Average runtime: 90.69318532943726 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 19:22:45.866341: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600000 exceeds 10% of free system memory.\n",
      "2022-03-20 19:22:45.985804: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600000 exceeds 10% of free system memory.\n",
      "2022-03-20 19:22:46.273837: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (16, 16) with 2 resizing layers, Average runtime: 335.5662431716919 (s)\n",
      "Image size: (32, 32) with 3 resizing layers, Average runtime: 1363.9864540576934 (s)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "latent_dim = 100\n",
    "image_sizes = [(4, 4), (8, 8), (16, 16), (32, 32)]\n",
    "batch_size = 32\n",
    "units_per_layer = 128\n",
    "resizing_layers = [0, 1, 2, 3]\n",
    "kernel_size = 3\n",
    "\n",
    "sizes_avg_runtimes = []\n",
    "for i in range(len(resizing_layers)):\n",
    "    dataset = make_dataset(image_sizes[i], batch_size)\n",
    "    \n",
    "    discriminator = make_discriminator_model(\n",
    "        input_shape=(image_sizes[i] + (3, )),\n",
    "        latent_dim=latent_dim,\n",
    "        units_per_layer=units_per_layer,\n",
    "        downsampling_layers=resizing_layers[i],\n",
    "        kernel_size=kernel_size\n",
    "    )\n",
    "\n",
    "    generator = make_generator_model(\n",
    "        latent_dim=latent_dim,\n",
    "        units_per_layer=units_per_layer,\n",
    "        upsampling_layers=resizing_layers[i],\n",
    "        kernel_size=kernel_size\n",
    "    )\n",
    "\n",
    "    @tf.function\n",
    "    def trainn_step(generator, discriminator, images):\n",
    "        return train_step(generator, discriminator, images)\n",
    "\n",
    "    avg_runtime = train(generator, discriminator, dataset, epochs)\n",
    "    print(f\"Image size: {image_sizes[i]} with {resizing_layers[i]} resizing layers, Average runtime: {avg_runtime} (s)\")\n",
    "    sizes_avg_runtimes.append(avg_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949222ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "latent_dim = 100\n",
    "image_size = (4, 4) # h x w\n",
    "batch_size = 16\n",
    "units_per_layers = [16, 32, 64, 128, 256]\n",
    "resizing_layers = 0\n",
    "kernel_size = 2\n",
    "\n",
    "dataset = make_dataset(image_size, batch_size)\n",
    "\n",
    "avg_runtimes = []\n",
    "for units_per_layer in units_per_layers:\n",
    "    discriminator = make_discriminator_model(\n",
    "        input_shape=(image_size + (3, )),\n",
    "        latent_dim=latent_dim,\n",
    "        units_per_layer=units_per_layer,\n",
    "        downsampling_layers=resizing_layers,\n",
    "        kernel_size=kernel_size\n",
    "    )\n",
    "\n",
    "    generator = make_generator_model(\n",
    "        latent_dim=latent_dim,\n",
    "        units_per_layer=units_per_layer,\n",
    "        upsampling_layers=resizing_layers,\n",
    "        kernel_size=kernel_size\n",
    "    )\n",
    "\n",
    "    @tf.function\n",
    "    def trainn_step(generator, discriminator, images):\n",
    "        return train_step(generator, discriminator, images)\n",
    "\n",
    "    avg_runtime = train(generator, discriminator, dataset, epochs)\n",
    "    print(f\"Units: {units_per_layer}, Average runtime: {avg_runtime} (s)\")\n",
    "    avg_runtimes.append(avg_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749601f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 4), dpi=100)\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "plt.xscale(\"log\", base=2)\n",
    "\n",
    "x = [16, 32, 64, 128, 256]\n",
    "#y = [11, 16, 32, 63, 120]\n",
    "y = avg_runtimes\n",
    "\n",
    "ax.plot(x, y, color='b', alpha=.75, lw=2, ls='-.', marker='v', markersize=10,\n",
    "     markerfacecolor='b', markeredgecolor='b', markeredgewidth=2, label=\"Dell Insprion-5558\")\n",
    "\n",
    "ax.plot(x, [1, 2, 2.5, 5, 10], color='g', alpha=.75, lw=2, ls='--', marker='o', markersize=10,\n",
    "        markerfacecolor='g', markeredgecolor='g', markeredgewidth=2, label=\"Kaggle környezet\")\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.grid(True, color='0.6', dashes=(5, 2, 1, 2))\n",
    "\n",
    "ax.set_title('Átlagos epoch futásidő a unitok számának függvényében')\n",
    "ax.set_ylabel('Futásidő (s)')\n",
    "ax.set_xlabel('Unitok száma (db)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_of_images(images, epoch):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((images[i].numpy() * 127.5 + 127.5).astype(\"uint32\"), interpolation=\"none\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "seed = tf.random.normal([16, latent_dim])\n",
    "images = generator(seed, training=False)\n",
    "plot_grid_of_images(images, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1baafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "saved = np.array(sizes_avg_runtimes)\n",
    "\n",
    "np.save(\"sizes_avg_runtime_laptop.npy\", saved)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
