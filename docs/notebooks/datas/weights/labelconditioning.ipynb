{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:16.222386Z","iopub.execute_input":"2022-03-18T16:30:16.222730Z","iopub.status.idle":"2022-03-18T16:30:16.228917Z","shell.execute_reply.started":"2022-03-18T16:30:16.222658Z","shell.execute_reply":"2022-03-18T16:30:16.227910Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"epochs = 50\nnumber_of_examples = 16\nbatch_size = 128\nlatent_dim = 100\nimage_size = (32, 32) # h x w\n\nimage_seed = tf.random.normal([number_of_examples, latent_dim])\nlabel_seed = tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5])\n\nnumber_of_classes = 10","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:16.231338Z","iopub.execute_input":"2022-03-18T16:30:16.232005Z","iopub.status.idle":"2022-03-18T16:30:16.245552Z","shell.execute_reply.started":"2022-03-18T16:30:16.231959Z","shell.execute_reply":"2022-03-18T16:30:16.243932Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n\nx_train = (x_train - 127.5) / 127.5 #Normalizing","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:16.248227Z","iopub.execute_input":"2022-03-18T16:30:16.248770Z","iopub.status.idle":"2022-03-18T16:30:17.757426Z","shell.execute_reply.started":"2022-03-18T16:30:16.248725Z","shell.execute_reply":"2022-03-18T16:30:17.756435Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices(\n    (x_train, y_train)\n).batch(batch_size, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:17.758950Z","iopub.execute_input":"2022-03-18T16:30:17.759377Z","iopub.status.idle":"2022-03-18T16:30:20.673871Z","shell.execute_reply.started":"2022-03-18T16:30:17.759322Z","shell.execute_reply":"2022-03-18T16:30:20.672840Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def make_generator_model(latent_dim):\n    noise = keras.layers.Input(shape=[latent_dim])\n    label = keras.layers.Input(shape=(1, ))\n    \n    label_embedding = keras.layers.Flatten()(keras.layers.Embedding(number_of_classes, latent_dim)(label))\n    \n    gen_input = keras.layers.Multiply()([noise, label_embedding])\n    \n    hidden = keras.layers.Reshape((1, 1, latent_dim))(gen_input)\n    \n    hidden = keras.layers.Conv2DTranspose(512, 4, 1, 'valid')(hidden)\n    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n    hidden = keras.layers.ReLU()(hidden)\n    \n    hidden = keras.layers.Conv2DTranspose(256, 4, 2, 'same')(hidden)\n    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n    hidden = keras.layers.ReLU()(hidden)\n    \n    hidden = keras.layers.Conv2DTranspose(128, 4, 2, 'same')(hidden)\n    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n    hidden = keras.layers.ReLU()(hidden)\n    \n    hidden = keras.layers.Conv2DTranspose(3, 4, 2, 'same')(hidden)\n    out = keras.layers.Activation(\"tanh\")(hidden)\n    \n    return keras.Model(inputs=[noise, label], outputs=out)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:20.678982Z","iopub.execute_input":"2022-03-18T16:30:20.679225Z","iopub.status.idle":"2022-03-18T16:30:20.692854Z","shell.execute_reply.started":"2022-03-18T16:30:20.679191Z","shell.execute_reply":"2022-03-18T16:30:20.691730Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"generator = make_generator_model(latent_dim)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:20.694912Z","iopub.execute_input":"2022-03-18T16:30:20.695606Z","iopub.status.idle":"2022-03-18T16:30:20.841691Z","shell.execute_reply.started":"2022-03-18T16:30:20.695549Z","shell.execute_reply":"2022-03-18T16:30:20.840655Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def make_discriminator_model():\n    image = keras.layers.Input(shape=(32, 32, 3))\n    \n    label = keras.layers.Input(shape=(1, ))\n    \n    hidden = keras.layers.GaussianNoise(0.1)(image)\n    \n    hidden = keras.layers.Conv2D(128, 4, 2, 'same')(hidden)\n    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n    hidden = keras.layers.ReLU()(hidden)\n    \n    hidden = keras.layers.Conv2D(256, 4, 2, 'same')(hidden)\n    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n    hidden = keras.layers.ReLU()(hidden)\n    \n    hidden = keras.layers.Conv2D(512, 4, 2, 'same')(hidden)\n    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n    hidden = keras.layers.ReLU()(hidden)\n    \n    hidden = keras.layers.Conv2D(100, 4, 1, 'valid')(hidden)\n    hidden = keras.layers.ReLU()(hidden)\n    features = keras.layers.Flatten()(hidden)\n    \n    label_embedding = keras.layers.Flatten()(keras.layers.Embedding(number_of_classes, latent_dim)(label))\n    \n    embedded_space = keras.layers.Multiply()([features, label_embedding]) \n    \n    hidden = keras.layers.Dropout(0.3)(embedded_space)\n    \n    out = keras.layers.Dense(1)(hidden)\n    \n    return keras.Model(inputs=[image, label], outputs=out)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:20.845071Z","iopub.execute_input":"2022-03-18T16:30:20.845268Z","iopub.status.idle":"2022-03-18T16:30:20.861718Z","shell.execute_reply.started":"2022-03-18T16:30:20.845242Z","shell.execute_reply":"2022-03-18T16:30:20.859851Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"discriminator = make_discriminator_model()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:20.863924Z","iopub.execute_input":"2022-03-18T16:30:20.864832Z","iopub.status.idle":"2022-03-18T16:30:20.986031Z","shell.execute_reply.started":"2022-03-18T16:30:20.864726Z","shell.execute_reply":"2022-03-18T16:30:20.985076Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.constant(np.full(real_output.shape, 0.9)), real_output)\n    fake_loss = cross_entropy(tf.constant(np.full(fake_output.shape, 0)), fake_output)\n    \n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\ngenerator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)\ndiscriminator_optimizer = keras.optimizers.Adam(4e-4, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:20.987861Z","iopub.execute_input":"2022-03-18T16:30:20.988069Z","iopub.status.idle":"2022-03-18T16:30:21.007116Z","shell.execute_reply.started":"2022-03-18T16:30:20.988029Z","shell.execute_reply":"2022-03-18T16:30:21.006158Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(images):\n    train_images, train_labels = images\n    \n    noise = tf.random.normal([batch_size, latent_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator((noise, train_labels), training=True)\n\n        real_output = discriminator((train_images, train_labels), training=True)\n        fake_output = discriminator((generated_images, train_labels), training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(\n        gen_loss,\n        generator.trainable_variables\n    )\n\n    gradients_of_discriminator = disc_tape.gradient(\n        disc_loss,\n        discriminator.trainable_variables\n    )\n\n    generator_optimizer.apply_gradients(\n        zip(gradients_of_generator,\n            generator.trainable_variables)\n        )\n    discriminator_optimizer.apply_gradients(\n        zip(gradients_of_discriminator,\n            discriminator.trainable_variables)\n        )\n\n    return (gen_loss, disc_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:21.008861Z","iopub.execute_input":"2022-03-18T16:30:21.009437Z","iopub.status.idle":"2022-03-18T16:30:21.057486Z","shell.execute_reply.started":"2022-03-18T16:30:21.009398Z","shell.execute_reply":"2022-03-18T16:30:21.056457Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def plot_grid_of_images(images, epoch):\n    plt.figure(figsize=(8, 8))\n\n    for i in range(images.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow((images[i].numpy() * 127.5 + 127.5).astype(\"uint32\"))\n        plt.axis('off')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:21.062394Z","iopub.execute_input":"2022-03-18T16:30:21.062623Z","iopub.status.idle":"2022-03-18T16:30:21.069155Z","shell.execute_reply.started":"2022-03-18T16:30:21.062580Z","shell.execute_reply":"2022-03-18T16:30:21.067958Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def train(dataset, epochs):\n    generator_losses = np.empty((0, 0), dtype=float)\n    discriminator_losses = np.empty((0, 0), dtype=float)\n    for epoch in range(epochs):\n        start = time.time()\n        \n        batch_generator_losses = np.empty((0, 0), dtype=float)\n        batch_discriminator_losses = np.empty((0, 0), dtype=float)\n        for (batch, image_batch) in enumerate(dataset):\n            gen_loss, disc_loss = train_step(image_batch)\n            \n            if batch % 500 == 0:\n                average_batch_loss =\\\n                   gen_loss.numpy()/int(image_batch[0].shape[1])\n                print(f\"\"\"Epoch {epoch+1}\n                        Batch {batch} Loss {average_batch_loss:.4f}\"\"\")\n\n            batch_generator_losses = np.append(batch_generator_losses, gen_loss)\n            batch_discriminator_losses = np.append(batch_discriminator_losses, disc_loss)\n        if generator_losses.shape == (0, 0):\n            generator_losses = batch_generator_losses\n            discriminator_losses = batch_discriminator_losses\n        else:\n            generator_losses = np.vstack(\n                [generator_losses, batch_generator_losses]\n            )\n            discriminator_losses = np.vstack(\n                [discriminator_losses, batch_discriminator_losses]\n            )\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n        example_images = generator((image_seed, label_seed), training=False)\n        plot_grid_of_images(example_images, epoch)\n\n    # Generating after the final epoch\n    #example_images = generator(seed, training=False)\n    #plot_grid_of_images(example_images, epoch)\n    \n    return (generator_losses, discriminator_losses)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:21.071324Z","iopub.execute_input":"2022-03-18T16:30:21.072345Z","iopub.status.idle":"2022-03-18T16:30:21.087957Z","shell.execute_reply.started":"2022-03-18T16:30:21.072061Z","shell.execute_reply":"2022-03-18T16:30:21.086606Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Training the model\n(generator_losses, discriminator_losses) = train(dataset, epochs)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:30:21.091971Z","iopub.execute_input":"2022-03-18T16:30:21.092440Z","iopub.status.idle":"2022-03-18T16:50:03.470410Z","shell.execute_reply.started":"2022-03-18T16:30:21.092407Z","shell.execute_reply":"2022-03-18T16:50:03.469551Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\nnoises = tf.random.normal([number_of_examples, latent_dim])\nfor i in range(10):\n    print(class_names[i])\n    \n    example_images = generator((noises, tf.constant(np.full(16, i))), training=False)\n    plot_grid_of_images(example_images, 0)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:53:37.984953Z","iopub.execute_input":"2022-03-18T16:53:37.985214Z","iopub.status.idle":"2022-03-18T16:53:46.310439Z","shell.execute_reply.started":"2022-03-18T16:53:37.985185Z","shell.execute_reply":"2022-03-18T16:53:46.309608Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"discriminator.save(\"discriminatorcifar10.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:54:51.954874Z","iopub.execute_input":"2022-03-18T16:54:51.955173Z","iopub.status.idle":"2022-03-18T16:54:52.016361Z","shell.execute_reply.started":"2022-03-18T16:54:51.955143Z","shell.execute_reply":"2022-03-18T16:54:52.015367Z"},"trusted":true},"execution_count":34,"outputs":[]}]}