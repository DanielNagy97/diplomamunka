{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c2500b",
   "metadata": {},
   "source": [
    "# Discriminator modell\n",
    "\n",
    "Ezen notebook egy áttekintő jegyzeként szolgál a GAN háló Diszkriminátorához.\n",
    "A legegyszerűbb architektúrát kívánom bemutatni, a DCGAN diszkriminátorát, amely több későbbi modell alapjául szolgált. Remek kiinduló alap lehet. A modellt a keras Sequential API segítségével állítottam össze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1c3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a2f72",
   "metadata": {},
   "source": [
    "## Architektúra\n",
    "\n",
    "A _Diszkriminátor_ modell lényegében egy bináris osztályozó, amely eldönti, hogy a bemenetül kapott kép valódi vagy hamis. A bemeneti kép konvolúciós rétegeken megy végig, majd a kimeneti rétegen sigmoid aktivációs függvény segítségével hozza meg a döntést.\n",
    "A konvolúciós rétegek segítségével a modell fel tudja tárni a képeken található jellegzetességeket. A képen található mintázatokat filterek segítségével tanulja meg, amelyek megadott kernelméretekben pásztázzák végig a bemenetet. Így az egyes konvolúciósrétegek kimeneteként egy olyan reprezentáció jön létre a bemeneti képről, amelyben érvényesülnek a pixeleket körülölelő további pixelek is. Ezáltal a kimeneti aktivációs függvény előtti réteg, a szerializáció (Flattening) kevésbé fogja a kép tartalmára vonatkozó információt rontani.\n",
    "Mivel a tanítóminta képeinek pixelértékeit normalizáltuk a [-1, 1] intervallumra, így a diszkriminátor a bemenetén is ilyen tulajdonságú képeket vár. (A tanítási folyamatról a GAN notebookban számolok be részletesebben)\n",
    "A Diszkriminátor felépítésben hasonlít a Generátorhoz, lényegében annak tükörképeként képzelhetjük el. Viszont a dekonvolúciós rétegek helyett konvolúciós rétegeket alkalmazunk benne, hiszen jelen esetben a felbontás-csökkentés a cél, hogy ezáltal a kép tartalmára vonatkozó információkat értelmezhető és feldolgozható formában kinyerje a végső döntéshez.\n",
    "\n",
    "Lényeges leírni részletesen, hogy hogy épül fel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f4c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation\n",
    "def add_downsampling_unit(model, filters, kernel_size, strides, padding):\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding, activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=4,\n",
    "            strides=2,\n",
    "            input_shape=(64, 64, 3),\n",
    "            padding=\"same\", activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    add_downsampling_unit(model, filters=128,\n",
    "                          kernel_size=4, strides=2, padding=\"same\")\n",
    "\n",
    "    add_downsampling_unit(model, filters=256,\n",
    "                          kernel_size=4, strides=2, padding=\"same\")\n",
    "\n",
    "    add_downsampling_unit(model, filters=512,\n",
    "                          kernel_size=4, strides=2, padding=\"same\")\n",
    "    \n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=1,\n",
    "            kernel_size=4,\n",
    "            strides=1,\n",
    "            padding=\"valid\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866bd265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        3136      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         524544    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 512)         2097664   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 1)           8193      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,764,737\n",
      "Trainable params: 2,764,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 15:34:52.504612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-21 15:34:52.504667: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-21 15:34:52.504703: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Inspiron-5558): /proc/driver/nvidia/version does not exist\n",
      "2022-02-21 15:34:52.505090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b19db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
