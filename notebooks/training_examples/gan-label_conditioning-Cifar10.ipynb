{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:07.115595Z",
     "iopub.status.busy": "2022-03-27T15:50:07.115116Z",
     "iopub.status.idle": "2022-03-27T15:50:07.121454Z",
     "shell.execute_reply": "2022-03-27T15:50:07.120560Z",
     "shell.execute_reply.started": "2022-03-27T15:50:07.115557Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:07.209462Z",
     "iopub.status.busy": "2022-03-27T15:50:07.209256Z",
     "iopub.status.idle": "2022-03-27T15:50:07.216672Z",
     "shell.execute_reply": "2022-03-27T15:50:07.215967Z",
     "shell.execute_reply.started": "2022-03-27T15:50:07.209438Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "number_of_examples = 16\n",
    "batch_size = 32\n",
    "latent_dim = 512\n",
    "image_size = (32, 32) # h x w\n",
    "\n",
    "image_seed = tf.random.normal([number_of_examples, latent_dim])\n",
    "label_seed = tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5])\n",
    "\n",
    "number_of_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:07.275843Z",
     "iopub.status.busy": "2022-03-27T15:50:07.275547Z",
     "iopub.status.idle": "2022-03-27T15:50:08.477428Z",
     "shell.execute_reply": "2022-03-27T15:50:08.476652Z",
     "shell.execute_reply.started": "2022-03-27T15:50:07.275815Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = (x_train - 127.5) / 127.5 #Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:08.479535Z",
     "iopub.status.busy": "2022-03-27T15:50:08.479271Z",
     "iopub.status.idle": "2022-03-27T15:50:11.051095Z",
     "shell.execute_reply": "2022-03-27T15:50:11.050355Z",
     "shell.execute_reply.started": "2022-03-27T15:50:08.479500Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)\n",
    ").batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:11.052762Z",
     "iopub.status.busy": "2022-03-27T15:50:11.052495Z",
     "iopub.status.idle": "2022-03-27T15:50:11.063936Z",
     "shell.execute_reply": "2022-03-27T15:50:11.063183Z",
     "shell.execute_reply.started": "2022-03-27T15:50:11.052725Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model(latent_dim):\n",
    "    noise = keras.layers.Input(shape=[latent_dim])\n",
    "    label = keras.layers.Input(shape=(1, ))\n",
    "    \n",
    "    label_embedding = keras.layers.Flatten()(keras.layers.Embedding(number_of_classes, latent_dim)(label))\n",
    "    \n",
    "    gen_input = keras.layers.Multiply()([noise, label_embedding])\n",
    "    \n",
    "    hidden = keras.layers.Reshape((1, 1, latent_dim))(gen_input)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(512, 4, 1, 'valid')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(256, 3, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(128, 3, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2DTranspose(3, 3, 2, 'same')(hidden)\n",
    "    out = keras.layers.Activation(\"tanh\")(hidden)\n",
    "    \n",
    "    return keras.Model(inputs=[noise, label], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:11.066534Z",
     "iopub.status.busy": "2022-03-27T15:50:11.066131Z",
     "iopub.status.idle": "2022-03-27T15:50:11.166876Z",
     "shell.execute_reply": "2022-03-27T15:50:11.166259Z",
     "shell.execute_reply.started": "2022-03-27T15:50:11.066497Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:41.265562Z",
     "iopub.status.busy": "2022-03-27T15:50:41.265292Z",
     "iopub.status.idle": "2022-03-27T15:50:41.275652Z",
     "shell.execute_reply": "2022-03-27T15:50:41.274777Z",
     "shell.execute_reply.started": "2022-03-27T15:50:41.265533Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    image = keras.layers.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    label = keras.layers.Input(shape=(1, ))\n",
    "    \n",
    "    hidden = keras.layers.GaussianNoise(0.1)(image)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(128, 3, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(256, 3, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(512, 3, 2, 'same')(hidden)\n",
    "    hidden = keras.layers.BatchNormalization(momentum=0.9)(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    \n",
    "    hidden = keras.layers.Conv2D(latent_dim, 4, 1, 'valid')(hidden)\n",
    "    hidden = keras.layers.ReLU()(hidden)\n",
    "    features = keras.layers.Flatten()(hidden)\n",
    "    \n",
    "    label_embedding = keras.layers.Flatten()(keras.layers.Embedding(number_of_classes, latent_dim)(label))\n",
    "    \n",
    "    embedded_space = keras.layers.Multiply()([features, label_embedding]) \n",
    "    \n",
    "    hidden = keras.layers.Dropout(0.3)(embedded_space)\n",
    "    \n",
    "    out = keras.layers.Dense(1)(hidden)\n",
    "    \n",
    "    return keras.Model(inputs=[image, label], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:42.101532Z",
     "iopub.status.busy": "2022-03-27T15:50:42.101277Z",
     "iopub.status.idle": "2022-03-27T15:50:42.189006Z",
     "shell.execute_reply": "2022-03-27T15:50:42.188311Z",
     "shell.execute_reply.started": "2022-03-27T15:50:42.101503Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:43.527242Z",
     "iopub.status.busy": "2022-03-27T15:50:43.526968Z",
     "iopub.status.idle": "2022-03-27T15:50:43.539702Z",
     "shell.execute_reply": "2022-03-27T15:50:43.538990Z",
     "shell.execute_reply.started": "2022-03-27T15:50:43.527200Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.constant(np.full(real_output.shape, 0.9)), real_output)\n",
    "    fake_loss = cross_entropy(tf.constant(np.full(fake_output.shape, 0)), fake_output)\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "discriminator_optimizer = keras.optimizers.Adam(4e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:44.282649Z",
     "iopub.status.busy": "2022-03-27T15:50:44.282127Z",
     "iopub.status.idle": "2022-03-27T15:50:44.291577Z",
     "shell.execute_reply": "2022-03-27T15:50:44.290254Z",
     "shell.execute_reply.started": "2022-03-27T15:50:44.282609Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    train_images, train_labels = images\n",
    "    \n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator((noise, train_labels), training=True)\n",
    "\n",
    "        real_output = discriminator((train_images, train_labels), training=True)\n",
    "        fake_output = discriminator((generated_images, train_labels), training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(\n",
    "        gen_loss,\n",
    "        generator.trainable_variables\n",
    "    )\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(\n",
    "        disc_loss,\n",
    "        discriminator.trainable_variables\n",
    "    )\n",
    "\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_generator,\n",
    "            generator.trainable_variables)\n",
    "        )\n",
    "    discriminator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_discriminator,\n",
    "            discriminator.trainable_variables)\n",
    "        )\n",
    "\n",
    "    return (gen_loss, disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T16:10:37.280989Z",
     "iopub.status.busy": "2022-03-27T16:10:37.280730Z",
     "iopub.status.idle": "2022-03-27T16:10:37.286867Z",
     "shell.execute_reply": "2022-03-27T16:10:37.285581Z",
     "shell.execute_reply.started": "2022-03-27T16:10:37.280961Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_grid_of_images(images, epoch):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(8, 8, i+1)\n",
    "        plt.imshow((images[i].numpy() * 127.5 + 127.5).astype(\"uint32\"), interpolation=\"none\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:44.942581Z",
     "iopub.status.busy": "2022-03-27T15:50:44.942121Z",
     "iopub.status.idle": "2022-03-27T15:50:44.952162Z",
     "shell.execute_reply": "2022-03-27T15:50:44.951359Z",
     "shell.execute_reply.started": "2022-03-27T15:50:44.942549Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    generator_losses = np.empty((0, 0), dtype=float)\n",
    "    discriminator_losses = np.empty((0, 0), dtype=float)\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        batch_generator_losses = np.empty((0, 0), dtype=float)\n",
    "        batch_discriminator_losses = np.empty((0, 0), dtype=float)\n",
    "        for (batch, image_batch) in enumerate(dataset):\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "            \n",
    "            if batch % 500 == 0:\n",
    "                average_batch_loss =\\\n",
    "                   gen_loss.numpy()/int(image_batch[0].shape[1])\n",
    "                print(f\"\"\"Epoch {epoch+1}\n",
    "                        Batch {batch} Loss {average_batch_loss:.4f}\"\"\")\n",
    "\n",
    "            batch_generator_losses = np.append(batch_generator_losses, gen_loss)\n",
    "            batch_discriminator_losses = np.append(batch_discriminator_losses, disc_loss)\n",
    "        if generator_losses.shape == (0, 0):\n",
    "            generator_losses = batch_generator_losses\n",
    "            discriminator_losses = batch_discriminator_losses\n",
    "        else:\n",
    "            generator_losses = np.vstack(\n",
    "                [generator_losses, batch_generator_losses]\n",
    "            )\n",
    "            discriminator_losses = np.vstack(\n",
    "                [discriminator_losses, batch_discriminator_losses]\n",
    "            )\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "        example_images = generator((image_seed, label_seed), training=False)\n",
    "        plot_grid_of_images(example_images, epoch)\n",
    "    \n",
    "    return (generator_losses, discriminator_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T15:50:49.091759Z",
     "iopub.status.busy": "2022-03-27T15:50:49.091080Z",
     "iopub.status.idle": "2022-03-27T16:06:32.726737Z",
     "shell.execute_reply": "2022-03-27T16:06:32.726066Z",
     "shell.execute_reply.started": "2022-03-27T15:50:49.091716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "(generator_losses, discriminator_losses) = train(dataset, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T16:12:00.227045Z",
     "iopub.status.busy": "2022-03-27T16:12:00.226791Z",
     "iopub.status.idle": "2022-03-27T16:12:15.490710Z",
     "shell.execute_reply": "2022-03-27T16:12:15.490053Z",
     "shell.execute_reply.started": "2022-03-27T16:12:00.227016Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "noises = tf.random.normal([48, latent_dim])\n",
    "for i in range(10):\n",
    "    print(class_names[i])\n",
    "    \n",
    "    example_images = generator((noises, tf.constant(np.full(48, i))), training=False)\n",
    "    plot_grid_of_images(example_images, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-27T15:50:11.303588Z",
     "iopub.status.idle": "2022-03-27T15:50:11.304276Z",
     "shell.execute_reply": "2022-03-27T15:50:11.304049Z",
     "shell.execute_reply.started": "2022-03-27T15:50:11.304024Z"
    }
   },
   "outputs": [],
   "source": [
    "generator.save(\"generatorcifar10.h5\")\n",
    "discriminator.save(\"discriminatorcifar10.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
